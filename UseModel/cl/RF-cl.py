import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# -------------------------------
# 1. è¯»å– Parquet æ•°æ®
# -------------------------------
print("Loading dataset from Parquet...")
df = pd.read_parquet("DataAfterBert/train_em_cl.parquet")

print(f"Dataset shape: {df.shape}")
print(f"Columns: {list(df.columns)}")

# -------------------------------
# 2. ç¡®å®šæ ‡ç­¾åˆ—ï¼ˆè¯·æ ¹æ®ä½ çš„æ•°æ®è°ƒæ•´ï¼‰
# -------------------------------
# ğŸ‘‰ å¸¸è§çš„æ ‡ç­¾åˆ—åï¼š'label', 'Label', 'class', 'Class', 'y' ç­‰
# å¦‚æœä¸ç¡®å®šï¼Œå¯ä»¥æ‰“å° df.columns æŸ¥çœ‹
label_column = "label"  # è¯·æ ¹æ®å®é™…åˆ—åä¿®æ”¹ï¼

if label_column not in df.columns:
    # å°è¯•å¸¸è§åç§°
    possible_labels = ['Label', 'class', 'Class', 'y']
    for col in possible_labels:
        if col in df.columns:
            label_column = col
            break
    else:
        raise ValueError(f"âŒ No label column found. Please specify one of: {df.columns}")

# -------------------------------
# 3. åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
# -------------------------------
# ç‰¹å¾åˆ—ï¼šæ‰€æœ‰ä»¥ 'embedding_dim_' å¼€å¤´çš„åˆ—
feature_columns = [col for col in df.columns if col.startswith("embedding_dim_")]

if len(feature_columns) == 0:
    raise ValueError("âŒ No embedding feature columns found! Check column name prefix.")

X = df[feature_columns].values        # ç‰¹å¾çŸ©é˜µ (N, 1024)
y = df[label_column].values           # æ ‡ç­¾å‘é‡ (N,)

print(f"Features shape: {X.shape}")
print(f"Labels shape: {y.shape}")
print(f"Unique classes: {np.unique(y)}")

# -------------------------------
# 4. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
# -------------------------------
test_size = 0.1
random_state = 42

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=test_size,
    random_state=random_state,
    stratify=y  # ä¿æŒç±»åˆ«æ¯”ä¾‹
)

print(f"Training samples: {X_train.shape[0]}")
print(f"Test samples: {X_test.shape[0]}")

# -------------------------------
# 5. è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
# -------------------------------
print("\nTraining Random Forest Classifier...")
rf_model = RandomForestClassifier(
    n_estimators=500,      # å†³ç­–æ ‘æ•°é‡
    max_depth=None,        # ä¸é™åˆ¶æ·±åº¦
    min_samples_split=5,   # å†…éƒ¨èŠ‚ç‚¹å†åˆ’åˆ†æ‰€éœ€æœ€å°æ ·æœ¬æ•°
    min_samples_leaf=2,    # å¶å­èŠ‚ç‚¹æœ€å°‘æ ·æœ¬æ•°
    n_jobs=-1,             # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
    random_state=random_state,
    verbose=0              # ä¸è¾“å‡ºè®­ç»ƒè¿‡ç¨‹
)

# è®­ç»ƒæ¨¡å‹
rf_model.fit(X_train, y_train)

# -------------------------------
# 6. é¢„æµ‹ä¸è¯„ä¼°
# -------------------------------
y_pred = rf_model.predict(X_test)

# å‡†ç¡®ç‡
acc = accuracy_score(y_test, y_pred)
print(f"\nâœ… Test Accuracy: {acc:.4f}")

# åˆ†ç±»æŠ¥å‘Šï¼ˆç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ï¼‰
print("\nğŸ“‹ Classification Report:")
print(classification_report(y_test, y_pred))

# -------------------------------
# 7. æ··æ·†çŸ©é˜µå¯è§†åŒ–
# -------------------------------
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=np.unique(y),
            yticklabels=np.unique(y))
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()

# -------------------------------
# 8. ï¼ˆå¯é€‰ï¼‰ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–ï¼ˆå‰20ä¸ªæœ€é‡è¦ç»´åº¦ï¼‰
# -------------------------------
top_k = 20
importance = rf_model.feature_importances_
top_indices = np.argsort(importance)[::-1][:top_k]
top_importance = importance[top_indices]
top_names = [f"dim_{i}" for i in top_indices]

plt.figure(figsize=(10, 6))
sns.barplot(x=top_importance, y=top_names, palette="viridis")
plt.title(f"Top {top_k} Important Embedding Dimensions")
plt.xlabel("Feature Importance")
plt.ylabel("Dimension")
plt.tight_layout()
plt.show()

# -------------------------------
# 9. ï¼ˆå¯é€‰ï¼‰ä¿å­˜æ¨¡å‹
# -------------------------------
import joblib

model_save_path = "../models/rf_protein_classifier.pkl"
joblib.dump(rf_model, model_save_path)
print(f"\nğŸ’¾ Model saved to '{model_save_path}'")