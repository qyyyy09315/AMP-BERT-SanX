import pandas as pd
import numpy as np
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import os

# -------------------------------
# 1. è¯»å–è®­ç»ƒé›† Parquet æ•°æ®ï¼ˆå…¨é‡ç”¨äºè®­ç»ƒï¼‰
# -------------------------------
print("Loading training dataset from Parquet...")
df_train = pd.read_parquet("./train_em_cl.parquet")

print(f"Training dataset shape: {df_train.shape}")
print(f"Columns: {list(df_train.columns)}")

# -------------------------------
# 2. ç¡®å®šæ ‡ç­¾åˆ—
# -------------------------------
label_column = "label"  # è¯·æ ¹æ®å®é™…åˆ—åä¿®æ”¹ï¼
if label_column not in df_train.columns:
    possible_labels = ['Label', 'class', 'Class', 'y']
    for col in possible_labels:
        if col in df_train.columns:
            label_column = col
            break
    else:
        raise ValueError(f"âŒ No label column found in training data. Available columns: {df_train.columns}")

# -------------------------------
# 3. åˆ†ç¦»è®­ç»ƒé›†ç‰¹å¾å’Œæ ‡ç­¾
# -------------------------------
feature_columns = [col for col in df_train.columns if col.startswith("embedding_dim_")]
if len(feature_columns) == 0:
    raise ValueError("âŒ No embedding feature columns found! Check column name prefix.")

X_train = df_train[feature_columns].values
y_train = df_train[label_column].values

print(f"Training Features shape: {X_train.shape}")
print(f"Training Labels shape: {y_train.shape}")
print(f"Unique classes in training set: {np.unique(y_train)}")

# -------------------------------
# 4. ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆSVM å¿…éœ€ï¼ï¼‰
# -------------------------------
print("\nStandardizing features with StandardScaler...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # æ‹Ÿåˆå¹¶è½¬æ¢è®­ç»ƒæ•°æ®

print("âœ… Feature scaling completed.")

# -------------------------------
# 5. è®­ç»ƒ SVM æ¨¡å‹ï¼ˆä½¿ç”¨å…¨é‡è®­ç»ƒæ•°æ®ï¼‰
# -------------------------------
print("\nâœ… Training SVM Classifier (RBF kernel) on FULL training set...")

# æ¨èå‚æ•°ï¼ˆé€‚ç”¨äºè›‹ç™½è´¨åµŒå…¥è¿™ç±»é«˜ç»´æ•°æ®ï¼‰
svm_model = SVC(
    kernel='rbf',           # RBF æ ¸é€šå¸¸æ˜¯æœ€ä½³èµ·ç‚¹
    C=1.0,                  # æ­£åˆ™åŒ–å¼ºåº¦ï¼Œå¯åç»­è°ƒä¼˜
    gamma='scale',          # è‡ªåŠ¨é€‚é…ç‰¹å¾å°ºåº¦
    random_state=42,
    verbose=False,
    probability=False       # è‹¥ä¸éœ€è¦é¢„æµ‹æ¦‚ç‡ï¼Œè®¾ä¸º False æå‡é€Ÿåº¦
)

# è®­ç»ƒæ¨¡å‹
svm_model.fit(X_train_scaled, y_train)
print("âœ… SVM Training completed.")

# -------------------------------
# 6. åŠ è½½ç‹¬ç«‹æµ‹è¯•é›†å¹¶è¯„ä¼°
# -------------------------------
test_data_path = "test_em_cl.parquet"
if not os.path.exists(test_data_path):
    raise FileNotFoundError(f"âŒ Test file not found: {test_data_path}")

print(f"\nLoading test dataset from '{test_data_path}'...")
df_test = pd.read_parquet(test_data_path)
print(f"Test dataset shape: {df_test.shape}")

# æ£€æŸ¥æ ‡ç­¾åˆ—
if label_column not in df_test.columns:
    raise ValueError(f"âŒ Label column '{label_column}' not found in test data. Available: {df_test.columns}")

# æå–æµ‹è¯•ç‰¹å¾å¹¶æ ‡å‡†åŒ–ï¼ˆä½¿ç”¨è®­ç»ƒé›†çš„ scalerï¼‰
X_test = df_test[feature_columns].values
y_test = df_test[label_column].values

X_test_scaled = scaler.transform(X_test)  # âš ï¸ åª transformï¼Œä¸ fitï¼

print(f"Test Features shape: {X_test.shape}")
print(f"Test Labels shape: {y_test.shape}")
print(f"Unique classes in test set: {np.unique(y_test)}")

# -------------------------------
# 7. åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹å’Œè¯„ä¼°
# -------------------------------
print("\nEvaluating on test set...")
y_pred = svm_model.predict(X_test_scaled)

# å‡†ç¡®ç‡
acc = accuracy_score(y_test, y_pred)
print(f"\nâœ… Test Accuracy: {acc:.4f}")

# åˆ†ç±»æŠ¥å‘Š
print("\nğŸ“‹ Classification Report:")
print(classification_report(y_test, y_pred))

# -------------------------------
# 8. æ··æ·†çŸ©é˜µå¯è§†åŒ–
# -------------------------------
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=np.unique(y_test),
            yticklabels=np.unique(y_test))
plt.title("Confusion Matrix - Test Set (SVM)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()

# -------------------------------
# 9. ä¿å­˜æ¨¡å‹å’Œ scalerï¼ˆé‡è¦ï¼æ¨ç†æ—¶éœ€è¦ scalerï¼‰
# -------------------------------
model_save_dir = "../models"
os.makedirs(model_save_dir, exist_ok=True)

# ä¿å­˜ SVM æ¨¡å‹
model_save_path = os.path.join(model_save_dir, "svm_protein_classifier.pkl")
joblib.dump(svm_model, model_save_path)

# ä¿å­˜ scalerï¼ˆå¿…é¡»ï¼å¦åˆ™æœªæ¥æ— æ³•é¢„æµ‹ï¼‰
scaler_save_path = os.path.join(model_save_dir, "feature_scaler.pkl")
joblib.dump(scaler, scaler_save_path)

print(f"\nğŸ’¾ Model saved to '{model_save_path}'")
print(f"ğŸ’¾ Scaler saved to '{scaler_save_path}'")