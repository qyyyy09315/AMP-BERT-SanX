import pandas as pd
from transformers import BertTokenizer, BertModel
import torch

# 1. è®¾ç½®è®¾å¤‡ï¼šä¼˜å…ˆä½¿ç”¨ GPU (CUDA)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# æœ¬åœ°æ¨¡å‹è·¯å¾„
model_dir = "./prot_bert_bfd"

# 2. åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹
tokenizer = BertTokenizer.from_pretrained(model_dir)
model = BertModel.from_pretrained(model_dir)
model.to(device)
model.eval()


# 3. è¯»å–åºåˆ—æ–‡ä»¶ - ä¿ç•™æ‰€æœ‰åˆ—
def read_sequences_with_metadata(file_path):
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(file_path)

    print(f"æ–‡ä»¶åˆ—å: {list(df.columns)}")
    print(f"æ–‡ä»¶å½¢çŠ¶: {df.shape}")

    # è¯»å–åºåˆ—åˆ—ï¼ˆç¬¬ä¸€åˆ—ï¼‰
    sequences = df.iloc[:, 0].dropna().tolist()
    print(f"è¯»å–åºåˆ—åˆ—: '{df.columns[0]}'")
    print(f"å‰3ä¸ªåºåˆ—é¢„è§ˆ: {sequences[:3]}")

    # ä¿ç•™å…¶ä»–åˆ—ï¼ˆLengthå’Œlabelï¼‰
    metadata_columns = df.columns[1:].tolist()  # ä»ç¬¬äºŒåˆ—å¼€å§‹çš„æ‰€æœ‰åˆ—
    metadata_df = df[metadata_columns].copy()

    print(f"ä¿ç•™çš„å…ƒæ•°æ®åˆ—: {metadata_columns}")

    return sequences, metadata_df


# 4. è·å–åµŒå…¥è¡¨ç¤º
def get_protein_embedding(sequence):
    # ç¡®ä¿åºåˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
    if isinstance(sequence, (int, float)):
        sequence = str(int(sequence))
    elif not isinstance(sequence, str):
        sequence = str(sequence)

    # å»é™¤å¯èƒ½çš„ç©ºæ ¼
    sequence = sequence.strip()

    # ProtBert è¦æ±‚æ°¨åŸºé…¸ä¹‹é—´æœ‰ç©ºæ ¼
    sequence = " ".join(list(sequence))

    # Tokenize å¹¶ç›´æ¥ç§»åŠ¨åˆ° GPU
    inputs = tokenizer(
        sequence,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=1024
    )

    # å°†è¾“å…¥å¼ é‡ç§»åŠ¨åˆ° GPU
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)

    # å– [CLS] token çš„ embedding
    cls_embedding = outputs.last_hidden_state[:, 0, :]  # (1, hidden_size)

    return cls_embedding.cpu()


# ä¸»ç¨‹åº
if __name__ == "__main__":
    # è¯»å–åºåˆ—å’Œå…ƒæ•°æ®
    sequences, metadata_df = read_sequences_with_metadata("Data/test_cl.csv")

    embeddings = []
    valid_sequences = []
    valid_indices = []  # è®°å½•æœ‰æ•ˆçš„ç´¢å¼•

    print(f"Processing {len(sequences)} sequences...")

    for i, seq in enumerate(sequences):
        # æ£€æŸ¥åºåˆ—æ˜¯å¦æœ‰æ•ˆ
        if pd.isna(seq) or seq == "":
            continue

        # ç¡®ä¿åºåˆ—æ˜¯å­—ç¬¦ä¸²
        if not isinstance(seq, str):
            seq = str(seq)

        # æ£€æŸ¥åºåˆ—é•¿åº¦
        if len(seq) == 0:
            continue

        try:
            emb = get_protein_embedding(seq)
            embeddings.append(emb)
            valid_sequences.append(seq)
            valid_indices.append(i)  # è®°å½•æœ‰æ•ˆåºåˆ—çš„åŸå§‹ç´¢å¼•

            if (i + 1) % 100 == 0:  # æ¯100ä¸ªåºåˆ—æ‰“å°ä¸€æ¬¡è¿›åº¦
                print(f"[{i + 1}/{len(sequences)}] Sequence: {seq[:10]}... -> Embedding shape: {emb.shape}")

        except Exception as e:
            print(f"[{i + 1}/{len(sequences)}] å¤„ç†åºåˆ—æ—¶å‡ºé”™: {e}")
            continue

    # æ‰€æœ‰ embedding å¤„ç†å®Œæ¯•
    print(f"âœ… Done! Got {len(embeddings)} embeddings.")

    # ä¿å­˜åµŒå…¥å‘é‡
    torch.save(embeddings, "DataAfterBert/test_em_cl.pt")
    print("ğŸ’¾ Embeddings saved to 'test_em_cl.pt'")


    # ä¿å­˜åŒ…å«å…ƒæ•°æ®çš„å®Œæ•´ç»“æœ
    print("\nä¿å­˜åŒ…å«å…ƒæ•°æ®çš„å®Œæ•´ç»“æœ...")

    # åªä¿ç•™æœ‰æ•ˆåºåˆ—å¯¹åº”çš„å…ƒæ•°æ®
    valid_metadata_df = metadata_df.iloc[valid_indices].reset_index(drop=True)

    # åˆ›å»ºå®Œæ•´çš„ç»“æœDataFrameï¼ˆä¸åŒ…å«sequenceåˆ—ï¼‰
    result_df = pd.DataFrame()

    # æ·»åŠ å…ƒæ•°æ®åˆ—
    for col in valid_metadata_df.columns:
        result_df[col] = valid_metadata_df[col].values

    # æ·»åŠ åµŒå…¥å‘é‡ä¿¡æ¯
    embeddings_array = torch.cat(embeddings, dim=0).numpy()
    result_df['embedding_vector'] = list(embeddings_array)

    # ä¿å­˜å®Œæ•´ç»“æœï¼ˆä¸åŒ…å«sequenceåˆ—ï¼‰
    result_df.to_csv("DataAfterBert/test_data_complete.csv", index=False)
    print("ğŸ’¾ å®Œæ•´æ•°æ®ä¿å­˜åˆ° 'test_data_complete.csv' (ä¸åŒ…å«sequenceåˆ—)")

    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
    print(f"\nç»“æœç»Ÿè®¡:")
    print(f"æœ‰æ•ˆåºåˆ—æ•°é‡: {len(valid_sequences)}")
    print(f"ä¿ç•™çš„å…ƒæ•°æ®åˆ—: {list(valid_metadata_df.columns)}")
    print(f"å®Œæ•´æ•°æ®å½¢çŠ¶: {result_df.shape}")

    # æ˜¾ç¤ºå‰å‡ è¡Œç»“æœ
    print(f"\nå‰3è¡Œå®Œæ•´æ•°æ®:")
    print(result_df.head(3))
    #ä¿å­˜çš„ç»“æœä¸ºtest_data_complete.csv