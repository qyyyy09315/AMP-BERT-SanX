from flask import Flask, request, jsonify, render_template
import torch
import joblib
import pandas as pd
import numpy as np
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import io
import base64

app = Flask(__name__)

# -------------------------------
# åŠ è½½æ¨¡å‹å’Œ scaler
# -------------------------------
model_path = "models/dnn_protein_classifier.pth"
scaler_path = "models/feature_scaler.pkl"

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ¨¡å‹å®šä¹‰ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
class ProteinDNN(torch.nn.Module):
    def __init__(self, input_dim, num_classes, hidden_dims=[512, 256, 128], dropout=0.3):
        super().__init__()
        layers = []
        prev_dim = input_dim
        for hidden_dim in hidden_dims:
            layers.append(torch.nn.Linear(prev_dim, hidden_dim))
            layers.append(torch.nn.BatchNorm1d(hidden_dim))
            layers.append(torch.nn.ReLU())
            layers.append(torch.nn.Dropout(dropout))
            prev_dim = hidden_dim
        layers.append(torch.nn.Linear(prev_dim, num_classes))
        self.network = torch.nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

# åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
checkpoint = torch.load(model_path, map_location=device)
input_dim = checkpoint['input_dim']
num_classes = checkpoint['num_classes']
hidden_dims = checkpoint['hidden_dims']
expected_feature_columns = sorted(checkpoint['feature_columns'])  # è®­ç»ƒæ—¶çš„ç‰¹å¾åˆ—ï¼ˆæ’åºï¼‰

model = ProteinDNN(input_dim, num_classes, hidden_dims)
model.load_state_dict(checkpoint['model_state_dict'])
model.to(device)
model.eval()

# åŠ è½½æ ‡å‡†åŒ–å™¨
scaler = joblib.load(scaler_path)

print("âœ… Model and scaler loaded successfully.")


# -------------------------------
# è·¯ç”±ï¼šä¸»é¡µ
# -------------------------------
@app.route('/')
def home():
    # å°†ç‰¹å¾åˆ—ä¼ é€’ç»™å‰ç«¯ï¼ˆç”¨äºæç¤ºï¼‰
    feature_cols = list(expected_feature_columns)
    return render_template('index.html', feature_columns=feature_cols)


# -------------------------------
# è·¯ç”±ï¼šä¸Šä¼  Parquet æ–‡ä»¶è¿›è¡Œé¢„æµ‹
# -------------------------------
@app.route('/predict_parquet', methods=['POST'])
def predict_parquet():
    if 'file' not in request.files:
        return jsonify({'error': 'No file uploaded'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400

    if not file.filename.endswith('.parquet'):
        return jsonify({'error': 'Only .parquet files are allowed'}), 400

    try:
        df = pd.read_parquet(file)
        print("ğŸ“ Columns in uploaded file:", df.columns.tolist())

        if 'label' not in df.columns:
            return jsonify({'error': "âŒ Column 'label' not found in the Parquet file."}), 400

        # âœ… ç¡®ä¿åªä½¿ç”¨è®­ç»ƒæ—¶çš„ç‰¹å¾åˆ—ï¼ˆ1024 åˆ—ï¼‰
        required_features = set(expected_feature_columns)
        available_features = set(df.columns) - {'label'}

        missing = required_features - available_features
        if missing:
            return jsonify({'error': f"ç¼ºå°‘å¿…è¦ç‰¹å¾åˆ—: {list(missing)}"}), 400

        extra = available_features - required_features
        if extra:
            print(f"âš ï¸ å¿½ç•¥é¢å¤–åˆ—: {list(extra)}")

        X = df[expected_feature_columns].values  # ä¸¥æ ¼å– 1024 åˆ—
        y_true = df['label'].values

        if X.shape[1] != input_dim:
            return jsonify({
                'error': f'Feature dimension mismatch after selection: expected {input_dim}, got {X.shape[1]}'
            }), 400

        # æ ‡å‡†åŒ– & é¢„æµ‹
        X_scaled = scaler.transform(X)
        X_tensor = torch.FloatTensor(X_scaled).to(device)

        with torch.no_grad():
            outputs = model(X_tensor)
            _, preds = torch.max(outputs, 1)
            y_pred = preds.cpu().numpy()

        acc = accuracy_score(y_true, y_pred)
        report = classification_report(y_true, y_pred, output_dict=True)
        cm = confusion_matrix(y_true, y_pred)

        # ç»˜å›¾
        plt.figure(figsize=(6, 5))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=sorted(np.unique(y_true)),
                    yticklabels=sorted(np.unique(y_true)))
        plt.title("Confusion Matrix")
        plt.xlabel("Predicted")
        plt.ylabel("True")
        buf = io.BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight')
        buf.seek(0)
        img_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')
        plt.close()

        results = df[expected_feature_columns].copy()
        results['true_label'] = y_true
        results['predicted_label'] = y_pred

        return jsonify({
            'accuracy': float(acc),
            'classification_report': report,
            'confusion_matrix_image': img_base64,
            'total_samples': len(df),
            'predictions': results.head(50).to_dict(orient='records')
        })

    except Exception as e:
        # âœ… å…³é”®ï¼šå¿…é¡»åœ¨è¿™é‡Œ returnï¼å¦åˆ™å‡½æ•°è¿”å› None
        return jsonify({'error': f"Processing error: {str(e)}"}), 500

    # âœ… ä¸è¦è®©å‡½æ•°è‡ªç„¶ç»“æŸï¼ä¸Šé¢å¿…é¡» return


if __name__ == '__main__':
    app.run(debug=True)